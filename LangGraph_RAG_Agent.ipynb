{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LjoHmCXS2Smx",
        "outputId": "efba5228-a012-49d9-ad9f-5310fd708a45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Usage:   \n",
            "  pip3 install [options] <requirement specifier> [package-index-options] ...\n",
            "  pip3 install [options] -r <requirements file> [package-index-options] ...\n",
            "  pip3 install [options] [-e] <vcs project url> ...\n",
            "  pip3 install [options] [-e] <local project path> ...\n",
            "  pip3 install [options] <archive url/path> ...\n",
            "\n",
            "no such option: -u\n"
          ]
        }
      ],
      "source": [
        "!pip install -qu langchain langchain-openai langchain-community langchain-core"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lioeBVPo2YAg"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "if not os.getenv(\"OPENAI_API_KEY\"):\n",
        "    os.environ[\"OPENAI_API_KEY\"] = \"secret\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cADwDN_Q2nw2"
      },
      "outputs": [],
      "source": [
        "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
        "os.environ[\"LANGSMITH_API_KEY\"] = \"secret\"\n",
        "os.environ[\"LANGSMITH_PROJECT\"] = \"langgraph-rag\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lo4uMa8m3S75",
        "outputId": "b1d28cae-045f-4e1f-dd7f-26f8ddbf6dbd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain_openai in /usr/local/lib/python3.11/dist-packages (0.3.29)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.74 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (0.3.74)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.86.0 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (1.99.1)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (0.10.0)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.74->langchain_openai) (0.4.12)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.74->langchain_openai) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.74->langchain_openai) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.74->langchain_openai) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.74->langchain_openai) (4.14.1)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.74->langchain_openai) (25.0)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.74->langchain_openai) (2.11.7)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain_openai) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain_openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain_openai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain_openai) (4.67.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2.32.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.86.0->langchain_openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.86.0->langchain_openai) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.86.0->langchain_openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.86.0->langchain_openai) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.74->langchain_openai) (3.0.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.74->langchain_openai) (3.11.1)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.74->langchain_openai) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.74->langchain_openai) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.74->langchain_openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.74->langchain_openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.74->langchain_openai) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (2.5.0)\n"
          ]
        }
      ],
      "source": [
        "pip install langchain_openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WX5CK5QX28FU"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3BoYpEf3Vzp",
        "outputId": "f33f20d3-17fe-44d2-abe7-d46e190d76c0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='Artificial intelligence (AI) refers to the simulation of human intelligence in machines that are programmed to think, learn, and make decisions. These machines can perform tasks that typically require human cognitive functions such as understanding language, recognizing patterns, solving problems, and adapting to new information. AI encompasses a variety of techniques including machine learning, natural language processing, computer vision, and robotics, and it is used in applications ranging from virtual assistants and recommendation systems to autonomous vehicles and medical diagnosis.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 94, 'prompt_tokens': 12, 'total_tokens': 106, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_6f2eabb9a5', 'id': 'chatcmpl-C33Uu7iuvWQE3MSwppszpYNttp5G4', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--03f0a3d6-db58-47fe-8cef-4cfee9990e3e-0', usage_metadata={'input_tokens': 12, 'output_tokens': 94, 'total_tokens': 106, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0.7)\n",
        "response = llm.invoke(\"What is artificial intelligence?\")\n",
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A59zK9NU3qRz",
        "outputId": "45cc47d9-f0db-4128-be58-14b83342a8f4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='Deep Learning is a subset of machine learning that uses neural networks with many layers to automatically learn patterns from large amounts of data. It excels at tasks like image and speech recognition by mimicking how the human brain processes information.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 44, 'prompt_tokens': 31, 'total_tokens': 75, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_6f2eabb9a5', 'id': 'chatcmpl-C33UvbYmcy50ZIIpqEwZY2Qibl5VZ', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--e75015f1-f2e7-43cd-a523-5f242165d0e3-0', usage_metadata={'input_tokens': 31, 'output_tokens': 44, 'total_tokens': 75, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.messages import SystemMessage, HumanMessage\n",
        "message = [\n",
        "    SystemMessage(content=\"You are a helpful AI Chatbot that explains complex topic simply\"),\n",
        "    HumanMessage(content=\"Explain about Deep Learning in 2 lines\")\n",
        "]\n",
        "response = llm.invoke(message)\n",
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WbHgDgQ4xgs",
        "outputId": "76d35d98-3672-4eba-978c-3c4c1088102a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Usage:   \n",
            "  pip3 install [options] <requirement specifier> [package-index-options] ...\n",
            "  pip3 install [options] -r <requirements file> [package-index-options] ...\n",
            "  pip3 install [options] [-e] <vcs project url> ...\n",
            "  pip3 install [options] [-e] <local project path> ...\n",
            "  pip3 install [options] <archive url/path> ...\n",
            "\n",
            "no such option: -u\n"
          ]
        }
      ],
      "source": [
        "pip install -qu duckduckgo-search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Av649i4Q42D7",
        "outputId": "dceaef60-72a4-4ec6-adcb-44d3199db38e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.11/dist-packages (0.3.27)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.74)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.26 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.27)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.42)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.12.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (8.5.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.10.1)\n",
            "Requirement already satisfied: langsmith>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.4.12)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.26->langchain_community) (0.3.9)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.26->langchain_community) (2.11.7)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain_community) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain_community) (4.14.1)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain_community) (25.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain_community) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain_community) (3.11.1)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain_community) (0.23.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.1.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.2.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain_community) (2.33.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.1.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: duckduckgo-search in /usr/local/lib/python3.11/dist-packages (8.1.1)\n",
            "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from duckduckgo-search) (8.2.1)\n",
            "Requirement already satisfied: primp>=0.15.0 in /usr/local/lib/python3.11/dist-packages (from duckduckgo-search) (0.15.0)\n",
            "Requirement already satisfied: lxml>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from duckduckgo-search) (5.4.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain_community\n",
        "!pip install -U duckduckgo-search\n",
        "from langchain_core.tools import tool\n",
        "from langchain_community.tools import DuckDuckGoSearchRun"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aEyXa5Jf5Fhb",
        "outputId": "fd92e2cc-3fe5-4ce2-c62f-4030a244c1b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "@tool #langchain automatically inspects the function (since langchain has a specific format for tools that the LLM understands)\n",
        "def calculator(expression: str) -> str:\n",
        "    \"\"\"Calculate mathematical expressions. Use this for any math calculations.\"\"\"\n",
        "    try:\n",
        "        result = eval(expression)\n",
        "        return f\"The result of {expression} is {result}\"\n",
        "    except Exception as e:\n",
        "        return f\"Error calculating {expression}: {str(e)}\"\n",
        "\n",
        "search_tool = DuckDuckGoSearchRun() #acess the information concurrently from the web (executes the search across the web)\n",
        "\n",
        "tools = [calculator, search_tool]\n",
        "llm_with_tools = llm.bind_tools(tools)\n",
        "response = llm_with_tools.invoke(\"What's 25 * 4 + 17?\")\n",
        "print(response.content) #no response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDu7aZO55ztJ",
        "outputId": "93d5bf88-1104-49a3-d2d3-c88b1cc3059b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_BPbG4HqINAwTfDcMu6DHysvk', 'function': {'arguments': '{\"expression\":\"25 * 4 + 17\"}', 'name': 'calculator'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 107, 'total_tokens': 127, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_6f2eabb9a5', 'id': 'chatcmpl-C33VGiB2lYK4xfzRz2U2pI5ZCgzsw', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--454b6a0b-56b6-464a-85b9-2762db1ebb29-0', tool_calls=[{'name': 'calculator', 'args': {'expression': '25 * 4 + 17'}, 'id': 'call_BPbG4HqINAwTfDcMu6DHysvk', 'type': 'tool_call'}], usage_metadata={'input_tokens': 107, 'output_tokens': 20, 'total_tokens': 127, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kok0dUaJ51qJ"
      },
      "outputs": [],
      "source": [
        "tool_map = {\n",
        "    'calculator': calculator,\n",
        "    'duckduckgo_search': search_tool,\n",
        "}\n",
        "\n",
        "def handle_tool_calls(response, tool_map):\n",
        "    if not getattr(response, 'tool_calls', None):\n",
        "        return\n",
        "    print(f\"Tool calls requested: {len(response.tool_calls)}\")\n",
        "    for tool_call in response.tool_calls:\n",
        "        tool_name = tool_call['name']\n",
        "        args = tool_call['args']\n",
        "        print(f\"Tool: {tool_name}\")\n",
        "        print(f\"Args: {args}\")\n",
        "\n",
        "        tool = tool_map.get(tool_name)\n",
        "        if tool:\n",
        "            result = tool.invoke(args)\n",
        "            preview = result[:200] + '...' if isinstance(result, str) and len(result) > 200 else result\n",
        "            print(f\"Tool result: {preview}\") #print first 200 chars for long response(e.g search)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOiH9p6-6_Bq",
        "outputId": "86ce4237-1cd6-4300-e5e1-b6e7249191e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Query: What's 25 * 4 + 17?\n",
            "Response: \n",
            "Tool calls requested: 1\n",
            "Tool: calculator\n",
            "Args: {'expression': '25 * 4 + 17'}\n",
            "Tool result: The result of 25 * 4 + 17 is 117\n",
            "\n",
            "\n",
            "\n",
            "Query: Search for recent news about artificial intelligence\n",
            "Response: \n",
            "Tool calls requested: 1\n",
            "Tool: duckduckgo_search\n",
            "Args: {'query': 'recent news about artificial intelligence'}\n",
            "Tool result: windows 11设置不显示最近打开文件的方法： 1、在开始界面点击设置 2、点击个性化 3、点击开始 4、点击关闭显示最近打开的 ... Oct 17, 2022 · recent文件查看 1/3 打开运行窗口 进入Windows页面后右键点击win图标，在菜单栏中点击【运行】，也可使用win+R键打开运行。 编辑于2022-04-10，内容仅供参考并受版权保护 对于很多已经把电脑Window...\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/langchain_community/utilities/duckduckgo_search.py:63: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
            "  with DDGS() as ddgs:\n"
          ]
        }
      ],
      "source": [
        "def test_llm_tool(query):\n",
        "    print(f\"Query: {query}\")\n",
        "    response = llm_with_tools.invoke(query) #llm.bind(calculator and search tools)\n",
        "    print(f\"Response: {getattr(response, 'content', response)}\")\n",
        "    handle_tool_calls(response, tool_map)\n",
        "    print('\\n\\n')\n",
        "\n",
        "test_llm_tool(\"What's 25 * 4 + 17?\")\n",
        "test_llm_tool(\"Search for recent news about artificial intelligence\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "id": "hVjRrp8N70Ms",
        "outputId": "c49e0f1e-a2c9-4c00-a054-a374e46763b7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/langchain_community/utilities/duckduckgo_search.py:63: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
            "  with DDGS() as ddgs:\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2 days ago · AI News reports on the latest artificial intelligence news and insights. Explore industry trends from the frontline of AI. 1 day ago · Get the latest AI news, live updates, and expert insights on artificial intelligence, machine learning, deep learning, and more at xix.ai. Handpicked daily for developers, … 3 days ago · All the latest breaking news on Artificial Intelligence. Browse Newsweek archives of photos, videos and articles on Artificial Intelligence. 6 days ago · Artificial intelligence has ushered in an era of what insiders in the nation’s innovation capital call “hard tech.” The Rationalists, a community focused on the risks of artificial … Jun 25, 2025 · Artificial Intelligence News. Everything on AI including futuristic robots with artificial intelligence, computer models of human intelligence and more.'"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#use of langchain expression language to invoke them directly (from duckduckgo search)\n",
        "search_tool.invoke(\"Search for recent news about artificial intelligence\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSOA78y08TXd"
      },
      "source": [
        "Structured Output LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "11d3iFJq8QQx"
      },
      "outputs": [],
      "source": [
        "from pydantic import BaseModel, Field\n",
        "from typing import List, Optional"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZuXPXNHV8p8J",
        "outputId": "c7dada70-711b-40d7-d42b-9fe273b253ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "structured output test: \n",
            "Name: John Smith\n",
            "Age: 35\n",
            "Occupation: software engineer\n",
            "Skills: machine learning, Python programming, cloud architecture, AI research\n"
          ]
        }
      ],
      "source": [
        "class PersonInfo(BaseModel):\n",
        "  name: str = Field(description=\"Full name of the person\")\n",
        "  age: Optional[int] = Field(description=\"Age of the person\")\n",
        "  occupation: str = Field(description=\"Person's job or profession\")\n",
        "  skills : List[str] = Field(description=\"List of skills or abilities\")\n",
        "\n",
        "structured_llm = llm.with_structured_output(PersonInfo)\n",
        "print(\"structured output test: \")\n",
        "person_prompt = \"\"\"\n",
        "Extract information about this person:\n",
        "'John Smith is a 35-year old software engineer who works at Google.\n",
        "He specializes in machine larning, Python programming and cloud architecture.\n",
        "John has been working in the tech for over 10 years and is passionate about AI research.\n",
        "\n",
        "\"\"\"\n",
        "person_result = structured_llm.invoke(person_prompt)\n",
        "print(f\"Name: {person_result.name}\")\n",
        "print(f\"Age: {person_result.age}\")\n",
        "print(f\"Occupation: {person_result.occupation}\")\n",
        "print(f\"Skills: {', '.join(person_result.skills)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9j72yG2PeJ7l"
      },
      "source": [
        "#Basic langgrapah chatbot\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2m2jZo1XfNt6"
      },
      "outputs": [],
      "source": [
        "!pip install -qU langgraph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Utv9hYXeNlV"
      },
      "outputs": [],
      "source": [
        "from typing import Annotated, TypedDict\n",
        "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage\n",
        "from langgraph.graph.message import add_messages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "laHCJ3RgfZDt"
      },
      "outputs": [],
      "source": [
        "class State(TypedDict):\n",
        "  ''' State for our Chatbot  - this holds the conversation history '''\n",
        "  #the add_message func handles appending new messages to the conversation\n",
        "  messages: Annotated[list[BaseMessage], add_messages] #when the state is updated then the add_message should be appended insetead of overwriting to the array\n",
        "\n",
        "llm = ChatOpenAI(model='gpt-4.1-mini', temperature=0.7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMQ54sYXf1n1",
        "outputId": "9b624161-447a-4208-e3dc-68136b9f3817"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Chatbot node function created\n"
          ]
        }
      ],
      "source": [
        "def chatbot_node(state: State) -> State:\n",
        "  ''' the main chatbot node that processes messages and generates responses '''\n",
        "  print(f\"processing {len(state['messages'])} messages\")\n",
        "\n",
        "  #get the response from the llm\n",
        "  response = llm.invoke(state['messages'])\n",
        "\n",
        "  #return the updated state with the new response\n",
        "  return {\"messages\": [response]}\n",
        "\n",
        "print(\"Chatbot node function created\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvyptI-rhD0p"
      },
      "source": [
        "#build the graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q1RxZBjGg5RM"
      },
      "outputs": [],
      "source": [
        "from langgraph.graph import StateGraph, START, END"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "BaP_4E-bhLNK",
        "outputId": "c901b29f-7724-4bb1-ef24-75ed8f6174a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "graph structure created\n",
            "graph compiled successfully\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "graph_builder = StateGraph(State)\n",
        "\n",
        "#add the chatbot node to the graph\n",
        "graph_builder.add_node(\"chatbot\", chatbot_node)\n",
        "\n",
        "#define the flow: start->chatbot->end\n",
        "graph_builder.add_edge(START, \"chatbot\")\n",
        "graph_builder.add_edge(\"chatbot\", END)\n",
        "\n",
        "#compile the graph\n",
        "graph = graph_builder.compile()\n",
        "\n",
        "print(\"graph structure created\")\n",
        "print(\"graph compiled successfully\")\n",
        "\n",
        "#visualize the graph\n",
        "\n",
        "img = graph.get_graph(xray=True).draw_mermaid_png()\n",
        "with open(\"graph.png\", \"wb\") as f:\n",
        "  f.write(img)\n",
        "\n",
        "from IPython.display import Image, display\n",
        "display(Image(\"graph.png\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbjUjUrYiSIQ"
      },
      "source": [
        "#Test the chatbot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVC7mRtliTyd",
        "outputId": "0cd3a45a-b7e1-437f-c316-fbd902e2ee3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " user: hello, my name Narmadha?\n",
            "processing 1 messages\n",
            "Assistent: Hello, Narmadha! How can I assist you today?\n",
            "\n",
            " user: Do you remember my name\n",
            "processing 1 messages\n",
            "Assistent: I don’t have a record of your name from our previous messages. What should I call you?\n"
          ]
        }
      ],
      "source": [
        "def test_chatbot(message: str):\n",
        "  '''helper functoin to test our chatbot'''\n",
        "  print(f\"\\n user: {message}\")\n",
        "\n",
        "  #create the initial state with the user message\n",
        "  initial_state = {\"messages\": [HumanMessage(content=message)]}\n",
        "\n",
        "  #run the graph\n",
        "  result = graph.invoke(initial_state)\n",
        "\n",
        "  #get the ai response\n",
        "  ai_response = result['messages'][-1].content\n",
        "  print(f\"Assistent: {ai_response}\")\n",
        "\n",
        "  return result\n",
        "\n",
        "#test with simple message\n",
        "test_cases = [\n",
        "    \"hello, my name Narmadha?\",\n",
        "    \"Do you remember my name\"\n",
        "]\n",
        "\n",
        "for test_message in test_cases:\n",
        "  test_chatbot(test_message)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArRaQRHlkmBt"
      },
      "source": [
        "#add memory to the chatbot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "99DWI9_2kjrn"
      },
      "outputs": [],
      "source": [
        "from langgraph.checkpoint.memory import MemorySaver"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwkJYigRktgc",
        "outputId": "9b262b3a-b9d1-4e0d-b01b-7c369a77142d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "memory added to chatbot\n",
            "\n",
            " testing convo with memo\n",
            "\n",
            " user: Hi, my name is Narmadha\n",
            "processing 1 messages\n",
            "Assistent: Hello Narmadha! How can I assist you today?\n",
            "\n",
            " user: What's my name?\n",
            "processing 3 messages\n",
            "Assistent: Your name is Narmadha. How can I help you further?\n",
            "\n",
            " user: Do you remember my name?\n",
            "processing 5 messages\n",
            "Assistent: Yes, I remember your name is Narmadha. How can I assist you today?\n"
          ]
        }
      ],
      "source": [
        "memory = MemorySaver()\n",
        "\n",
        "#compile the graph with memory\n",
        "graph_with_memory = graph_builder.compile(checkpointer=memory)\n",
        "\n",
        "print(\"memory added to chatbot\")\n",
        "\n",
        "def chat_with_memory(message: str, thread_id: str):\n",
        "  '''chat function with memory '''\n",
        "  print(f\"\\n user: {message}\")\n",
        "\n",
        "  #configuration for the thread\n",
        "  config = {'configurable': {'thread_id': thread_id}}\n",
        "\n",
        "  #create the initial state with the user message to conversation\n",
        "  initial_state = {\"messages\": [HumanMessage(content=message)]}\n",
        "\n",
        "  #run the graph with memory\n",
        "  result = graph_with_memory.invoke(initial_state, config)\n",
        "\n",
        "  #get the ai response\n",
        "  ai_response = result['messages'][-1].content\n",
        "  print(f\"Assistent: {ai_response}\")\n",
        "\n",
        "  #test conversation with memory\n",
        "print('\\n testing convo with memo')\n",
        "\n",
        "chat_with_memory(\"Hi, my name is Narmadha\", thread_id=\"thread-1\")\n",
        "chat_with_memory(\"What's my name?\", thread_id=\"thread-1\")\n",
        "chat_with_memory(\"Do you remember my name?\", thread_id=\"thread-1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sq91IlIpmzcF"
      },
      "source": [
        "#3. langgraph agent with tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SWCtGmL6m9TO"
      },
      "outputs": [],
      "source": [
        "class AgentState(TypedDict):\n",
        "  '''state for our two-node agent'''\n",
        "  messages: Annotated[list[BaseMessage], add_messages]\n",
        "\n",
        "#initialize llm with tools\n",
        "llm = ChatOpenAI(model='gpt-4.1-mini', temperature =0.7)\n",
        "llm_with_tools=llm.bind_tools(tools)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vABpmjbm33b"
      },
      "source": [
        "creating chatbot node"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E12URmX3nY4S",
        "outputId": "32216305-8b29-4fd9-e690-973746c2b9b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "chatbot node created\n"
          ]
        }
      ],
      "source": [
        "def chatbot_node(state: AgentState) -> AgentState:\n",
        "  '''the chatbot node that decideds whethr to use tools or provide direct responses'''\n",
        "  messages = state[\"messages\"]\n",
        "\n",
        "  #add system prompt\n",
        "  system_message = '''you are a helpful ai assistent. You have access to web search and calculator tools.\n",
        "\n",
        "  Use the web_seach tool when:\n",
        "  - asked about current events, news, or recent information\n",
        "  - need to find specific facts or data\n",
        "  - asked about real-time informaion(weather, stock prices, etc.)\n",
        "\n",
        "  use the calculator tool when:\n",
        "  - asked to perform mathematical calculations\n",
        "  - need to solve math problems\n",
        "\n",
        "  for general knowledge questions that don't require real-time data, answer directly\n",
        "  be helpful and conversational in your response. '''\n",
        "\n",
        "  #prepare messages woth system prompts\n",
        "  all_messages = [{'role':\"system\", \"content\": system_message}] + messages\n",
        "\n",
        "  #get response from llm\n",
        "  response = llm_with_tools.invoke(all_messages)\n",
        "\n",
        "  return {'messages':[response]}\n",
        "\n",
        "print('chatbot node created')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjSEqfuUviLn"
      },
      "source": [
        "#creating tool node and routing logic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LoRhd5SsvkL3"
      },
      "outputs": [],
      "source": [
        "from langgraph.prebuilt import ToolNode\n",
        "from typing import Literal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSQgURMovqGl",
        "outputId": "b989c434-8e0b-411a-e0ec-619b5bb12a2f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[StructuredTool(name='calculator', description='Calculate mathematical expressions. Use this for any math calculations.', args_schema=<class 'langchain_core.utils.pydantic.calculator'>, func=<function calculator at 0x7b98b257f420>),\n",
              " DuckDuckGoSearchRun(api_wrapper=DuckDuckGoSearchAPIWrapper(region='wt-wt', safesearch='moderate', time='y', max_results=5, backend='auto', source='text'))]"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NbZXqxT_vsjj",
        "outputId": "09267e3a-7796-48a3-f169-3c94045ab760"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tool node created\n",
            "Routing logic created\n"
          ]
        }
      ],
      "source": [
        "\n",
        "tool_node = ToolNode(tools)\n",
        "\n",
        "print(\"Tool node created\")\n",
        "\n",
        "\n",
        "def should_continue(state: AgentState) -> Literal[\"tools\", \"end\"]:\n",
        "    \"\"\"\n",
        "    Determine whether to continue to tools or end the conversation\n",
        "    \"\"\"\n",
        "    messages = state[\"messages\"]\n",
        "    last_message = messages[-1]\n",
        "\n",
        "    # If the last message has tool calls, go to tools\n",
        "    if hasattr(last_message, 'tool_calls') and last_message.tool_calls:\n",
        "        return \"tools\"\n",
        "    # Otherwise, end the conversation\n",
        "    else:\n",
        "        return \"end\"\n",
        "\n",
        "print(\"Routing logic created\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6na8BjSw1NF"
      },
      "source": [
        "#building graph\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tO8WRGM8wvEz"
      },
      "outputs": [],
      "source": [
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.checkpoint.memory import MemorySaver"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        },
        "id": "AYgwMcNLxBt-",
        "outputId": "8f332d81-43bd-4802-e3d3-1727e13742a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Graph compiled with memory\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "workflow = StateGraph(AgentState)\n",
        "\n",
        "# Add nodes\n",
        "workflow.add_node(\"chatbot\", chatbot_node)\n",
        "workflow.add_node(\"tools\", tool_node)\n",
        "\n",
        "# Set entry point\n",
        "workflow.add_edge(START, \"chatbot\")\n",
        "\n",
        "# Add conditional edges\n",
        "workflow.add_conditional_edges(\n",
        "    \"chatbot\",\n",
        "    should_continue,\n",
        "    {\n",
        "        \"tools\": \"tools\",\n",
        "        \"end\": END,\n",
        "    },\n",
        ")\n",
        "\n",
        "# After using tools, go back to chatbot\n",
        "workflow.add_edge(\"tools\", \"chatbot\")\n",
        "\n",
        "# Compile the graph\n",
        "memory = MemorySaver()\n",
        "app = workflow.compile(checkpointer=memory)\n",
        "\n",
        "print(\"Graph compiled with memory\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# VISUALIZE THE GRAPH\n",
        "# ============================================================================\n",
        "img = app.get_graph(xray=True).draw_mermaid_png()\n",
        "with open(\"graph.png\", \"wb\") as f:\n",
        "    f.write(img)\n",
        "\n",
        "from IPython.display import Image, display\n",
        "display(Image(\"graph.png\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETFMudMq8tqn"
      },
      "source": [
        "#testing agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FR5BBCQW8vxl",
        "outputId": "4ace0837-a778-4189-b23f-3ade91cd6d16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "User: i am narmadha\n",
            "\n",
            "👤 User: i am narmadha\n",
            "🤖 Assistant: Got it, Narmadha! How can I assist you today?\n",
            "User: do you remember my name\n",
            "\n",
            "👤 User: do you remember my name\n",
            "🤖 Assistant: Yes, you mentioned your name is Narmadha. How can I help you today, Narmadha?\n",
            "User: what's 15% of 240\n",
            "\n",
            "👤 User: what's 15% of 240\n",
            "🤖 Assistant: 15% of 240 is 36. If you need help with anything else, feel free to ask!\n",
            "User: what's the latest news about artificial intellegence?\n",
            "\n",
            "👤 User: what's the latest news about artificial intellegence?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/langchain_community/utilities/duckduckgo_search.py:63: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
            "  with DDGS() as ddgs:\n",
            "sys:1: ResourceWarning: Unclosed socket <zmq.Socket(zmq.PUSH) at 0x7b98b0e74050>\n",
            "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔧 Tool Result: Breaking news from Hong Kong, China and Asia including geopolitics, diplomacy, economy, technology, ...\n",
            "🤖 Assistant: I found some search results, but they do not seem to include the latest news about artificial intelligence specifically. Let me try again to find the most recent updates on artificial intelligence.\n",
            "🔧 Tool Result: Breaking news from Hong Kong, China and Asia including geopolitics, diplomacy, economy, technology, ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/langchain_community/utilities/duckduckgo_search.py:63: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
            "  with DDGS() as ddgs:\n",
            "sys:1: ResourceWarning: Unclosed socket <zmq.Socket(zmq.PUSH) at 0x7b98b0f33850>\n",
            "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🤖 Assistant: It seems the search results are not showing the latest specific news about artificial intelligence. If you want, I can provide a summary of recent trends and developments in AI based on what is generally known up to now. Would you like me to do that?\n",
            "User: can you tell me more about that?\n",
            "\n",
            "👤 User: can you tell me more about that?\n",
            "🤖 Assistant: Certainly! Here’s a summary of some recent trends and developments in artificial intelligence as of 2024:\n",
            "\n",
            "1. **Generative AI Advances**: Models like GPT-4 and other large language models have continued to improve, enabling more natural and creative text generation. These models are being integrated into various applications including chatbots, content creation tools, and programming assistants.\n",
            "\n",
            "2. **AI in Healthcare**: AI is increasingly used for diagnostics, drug discovery, and personalized medicine. Algorithms help analyze medical images, predict patient outcomes, and assist in clinical decision-making.\n",
            "\n",
            "3. **Ethics and Regulation**: With AI’s growing impact, there is more focus on ethical considerations such as bias, privacy, and transparency. Governments and organizations are working on regulations to ensure responsible AI use.\n",
            "\n",
            "4. **AI and Automation**: AI-powered automation is transforming industries like manufacturing, logistics, and customer service, improving efficiency and reducing costs.\n",
            "\n",
            "5. **Multimodal AI**: Advances in models that can process and generate multiple types of data (text, images, audio) simultaneously are enabling new applications like AI-powered design tools and virtual assistants.\n",
            "\n",
            "6. **AI for Climate and Environment**: AI is being used to model climate change, optimize energy use, and support environmental conservation efforts.\n",
            "\n",
            "If you want, I can also help find specific recent news articles or research papers on any of these topics!\n",
            "User: exit\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.messages import HumanMessage, AIMessage, ToolMessage\n",
        "def chat_with_agent(message: str, thread_id: str):\n",
        "    \"\"\"Chat with the two-node agent\"\"\"\n",
        "    print(f\"\\n👤 User: {message}\")\n",
        "\n",
        "    config = {\"configurable\": {\"thread_id\": thread_id}}\n",
        "\n",
        "    # Stream the response to see the process\n",
        "    messages_to_process = {\"messages\": [HumanMessage(content=message)]}\n",
        "\n",
        "    for event in app.stream(messages_to_process, config):\n",
        "        for value in event.values():\n",
        "            if \"messages\" in value:\n",
        "                last_message = value[\"messages\"][-1]\n",
        "                if hasattr(last_message, 'content') and last_message.content:\n",
        "                    if isinstance(last_message, AIMessage):\n",
        "                        print(f\" Assistant: {last_message.content}\")\n",
        "                    elif isinstance(last_message, ToolMessage):\n",
        "                        print(f\" Tool Result: {last_message.content[:100]}...\")\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"User: \")\n",
        "    if user_input.lower() == \"exit\":\n",
        "        break\n",
        "    chat_with_agent(user_input, thread_id=\"thread-2\")\n",
        "\n",
        "\n",
        "#question\n",
        "#i am narmadha\n",
        "#do you remember my name\n",
        "#what's 15%of 240?\n",
        "#what's the latest news about ai?\n",
        "#follow-up: can you tell me more about that?"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
